# -*- coding: utf-8 -*-
"""Prueba_Banistmo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aBPJ93x2RNHuGsjO5ZW-fTuI3bGW9ZUo

# Prueba de Banistmo - Probabilidad de Pago

Paso 1: Se instalan las librerias que sean necesarias.
"""

#pip install pandas

#pip install fastapi

#!pip install pycaret

#pip install numpy

#pip install uvicorn

#pip install lightgbm

#pip install autoviz

#pip install setuptools numpy scipy scikit-learn -U

#pip install --use-deprecated=legacy-resolver pycaret[full]

"""Fue Necesario ejecutar en la consola el homebrew:
#/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

Se importan las liberias necesarias:
"""

import numpy as np

import pandas as pd

import pycaret as pycaret

import lightgbm as lgb

"""##Para acceder al dataset:"""

dataset = pd.read_csv("./default_dataset.csv")

"""Para visualizar la data y los campos incluidos en el dataset ejecutamos:"""

dataset.head(5)

"""Para conocer la cantidad de datos que incluye el dataset en columnas y filas."""

dataset.shape

"""Fracciono la data y la muestra que compararé"""

data = dataset.sample(frac=0.95, random_state=766)
data_unseen = dataset.drop(data.index)
data.reset_index(inplace=True,drop=True)
data_unseen.reset_index(inplace=True,drop=True)
print("Data para Modelar: " + str(data.shape))
print("Data de Control para Predición: " + str(data_unseen.shape))

"""Importo la función que contiene los modelos de clasificación con lo que evaluaré la data:"""

from pycaret.classification import *

"""Configuración de los paramentos para la evaluación de la data

Para el ejercicio configuro 3 variables con diferentes paramentros para ver cual haria que el modelo sea mas efectivo.

-Me decidí por la variable banp1, debido a de las 3 configuraciones que probé, esa fue la que mejor desempeño mostró a la hora de evaluar la muestra en el modelo.
"""

banp1 = setup(data=data,target='default',session_id=123,fix_imbalance=True,ignore_low_variance = True)

banp2 = setup(data = data, target = 'default', session_id=123,
              normalize = True, 
                  transformation = True, 
                  ignore_low_variance = True,
                  remove_multicollinearity = True,
              pca=False,
              fix_imbalance = True ,
              group_features = [['BILL_AMT1', 'BILL_AMT2','BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6'],
                                   ['PAY_AMT1','PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']])

banp3 = setup(data = data, target = 'default', session_id=123,
              normalize = True, 
                  transformation = True, 
                  ignore_low_variance = True,
              pca=False,
              fix_imbalance = True )

"""Comparo todos los modelos y selecciono el Top 3."""

compare_models(n_select = 3)

"""En este caso, considero que lightgbm me es mas funcional debido a que su accuracy y su precisión son altas y su tiempo de ejecución es mucho mas bajo comparado a los otros 2 modelos.

#Creo mi modelo al cual le pongo de nombre Mocca:
"""

mocca = create_model('lightgbm')

"""Muestro los parametros actuales del modelo que elegí"""

print(mocca)

"""Evaluo el modelo """

evaluate_model(mocca)

"""Se tunea el modelo"""

tuned_mocca = tune_model(mocca)

"""Se muestran los nuevos parametros asignados al modelo tuneado:"""

print(tuned_mocca)

plot_model(mocca, plot='auc')

plot_model(tuned_mocca,plot='auc')

plot_model(tuned_mocca,plot='confusion_matrix')

predict_model(tuned_mocca)

"""Creo el dashboard explicativo del modelo y consigo la dirección html"""

dashboard(tuned_mocca)

"""Guardo el Modelo creado."""

save_model(tuned_mocca, 'predicted_mocca')

"""Carga del Modelo"""

loaded_model = load_model('predicted_mocca')

"""Muestro los parametros del Modelo creado."""

print(loaded_model)